{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d55f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved formatted training data to train_formatted.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your training data\n",
    "df = pd.read_csv(\"/Users/pennatarunkumar/Documents/llm-classification-finetuning/train.csv\")\n",
    "\n",
    "# Create the text_input column by combining prompt + response_a + response_b\n",
    "df[\"text_input\"] = (\n",
    "    \"Prompt: \" + df[\"prompt\"] + \n",
    "    \" \\nResponse A: \" + df[\"response_a\"] + \n",
    "    \" \\nResponse B: \" + df[\"response_b\"]\n",
    ")\n",
    "\n",
    "# Create label based on winner_a and winner_b\n",
    "def decide_winner(row):\n",
    "    if row[\"winner_model_a\"] > row[\"winner_model_b\"]:\n",
    "        return \"A\"\n",
    "    elif row[\"winner_model_b\"] > row[\"winner_model_a\"]:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"winner_tie\"\n",
    "\n",
    "df[\"label\"] = df.apply(decide_winner, axis=1)\n",
    "\n",
    "# Keep only the necessary columns\n",
    "df = df[[\"text_input\", \"label\"]]\n",
    "\n",
    "# Save the formatted file\n",
    "df.to_csv(\"train_formatted.csv\", index=False)\n",
    "\n",
    "print(\"Saved formatted training data to train_formatted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c791c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'test_formatted.csv' saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your test.csv file (make sure it's in the same folder as your notebook)\n",
    "df_test = pd.read_csv(\"/Users/pennatarunkumar/Documents/llm-classification-finetuning/test.csv\")\n",
    "\n",
    "# Combine prompt + responses into one text_input column, matching training format\n",
    "df_test[\"text_input\"] = (\n",
    "    \"Prompt: \" + df_test[\"prompt\"] +\n",
    "    \" \\nResponse A: \" + df_test[\"response_a\"] +\n",
    "    \" \\nResponse B: \" + df_test[\"response_b\"]\n",
    ")\n",
    "\n",
    "# Keep only 'id' and 'text_input' for prediction input\n",
    "df_test_formatted = df_test[[\"id\", \"text_input\"]]\n",
    "\n",
    "# Save to a new CSV file for model prediction\n",
    "df_test_formatted.to_csv(\"test_formatted.csv\", index=False)\n",
    "\n",
    "print(\"File 'test_formatted.csv' saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18d2b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/09/c9/5f0be8e51d55df60a1bd7d09e7b05380e04c38de9554105f6cacffac3886/xgboost-3.0.2-py3-none-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading xgboost-3.0.2-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading xgboost-3.0.2-py3-none-macosx_12_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d859bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text_input', 'label']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/pennatarunkumar/Documents/llm-classification-finetuning/train_formatted.csv\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c63fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fill NaNs just in case\n",
    "df[\"text_input\"] = df[\"text_input\"].fillna(\"\")\n",
    "\n",
    "# Vectorize\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text_input\"])\n",
    "y = df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd5af5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(df_filtered[\"text_input\"].apply(type).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58fa41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"text_input\"] = df_filtered[\"text_input\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da363c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, txt in enumerate(df_filtered[\"text_input\"].head(10)):\n",
    "    print(f\"--- Sample {i} ---\")\n",
    "    print(repr(txt))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c030244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered rows: 39716\n",
      "label\n",
      "0    20064\n",
      "1    19652\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map string labels to integers\n",
    "label_map = {\"A\": 0, \"B\": 1}\n",
    "\n",
    "# Filter out ties and map\n",
    "df = df[df[\"label\"].isin(label_map.keys())].copy()\n",
    "df[\"label\"] = df[\"label\"].map(label_map)\n",
    "\n",
    "print(\"Filtered rows:\", len(df))\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0be1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Clean text_input\n",
    "df[\"text_input\"] = df[\"text_input\"].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text_input\"])\n",
    "y = df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "679ee0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [11:03:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.513595166163142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.51      0.58      0.54      1980\n",
      "           B       0.52      0.45      0.48      1992\n",
      "\n",
      "    accuracy                           0.51      3972\n",
      "   macro avg       0.51      0.51      0.51      3972\n",
      "weighted avg       0.51      0.51      0.51      3972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred, target_names=[\"A\", \"B\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61d333ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows before filtering: 57477\n",
      "['text_input', 'label']\n",
      "                                          text_input       label\n",
      "0  Prompt: [\"Is it morally right to try to have a...           A\n",
      "1  Prompt: [\"What is the difference between marri...           B\n",
      "2  Prompt: [\"explain function calling. how would ...  winner_tie\n",
      "3  Prompt: [\"How can I create a test set for a ve...           A\n",
      "4  Prompt: [\"What is the best way to travel from ...           B\n",
      "Total rows after filtering ties: 39716\n",
      "label\n",
      "0    20064\n",
      "1    19652\n",
      "Name: count, dtype: int64\n",
      "TF-IDF matrix shape: (39716, 5000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pennatarunkumar/anaconda3/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [11:04:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.513595166163142\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.51      0.58      0.54      1980\n",
      "           B       0.52      0.45      0.48      1992\n",
      "\n",
      "    accuracy                           0.51      3972\n",
      "   macro avg       0.51      0.51      0.51      3972\n",
      "weighted avg       0.51      0.51      0.51      3972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Load data\n",
    "df = pd.read_csv(\"/Users/pennatarunkumar/Documents/llm-classification-finetuning/train_formatted.csv\")\n",
    "\n",
    "print(f\"Total rows before filtering: {len(df)}\")\n",
    "print(df.columns.tolist())\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Map string labels to integers and filter out ties\n",
    "label_map = {\"A\": 0, \"B\": 1}\n",
    "df = df[df[\"label\"].isin(label_map.keys())].copy()\n",
    "df[\"label\"] = df[\"label\"].map(label_map)\n",
    "\n",
    "print(f\"Total rows after filtering ties: {len(df)}\")\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "# Step 3: Clean text column\n",
    "df[\"text_input\"] = df[\"text_input\"].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "# Step 4: Vectorize text with TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df[\"text_input\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {X.shape}\")\n",
    "\n",
    "# Step 5: Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Step 6: Initialize and train XGBoost classifier\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Predict and evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred, target_names=[\"A\", \"B\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ef9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test data & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7780623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rows: 3\n",
      "['id', 'text_input']\n",
      "        id                                         text_input\n",
      "0   136060  Prompt: [\"I have three oranges today, I ate an...\n",
      "1   211333  Prompt: [\"You are a mediator in a heated polit...\n",
      "2  1233961  Prompt: [\"How to initialize the classification...\n",
      "  winner\n",
      "0      A\n",
      "1      B\n",
      "2      B\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"/Users/pennatarunkumar/Documents/llm-classification-finetuning/test_formatted.csv\")\n",
    "\n",
    "print(f\"Test rows: {len(test_df)}\")\n",
    "print(test_df.columns.tolist())\n",
    "print(test_df.head())\n",
    "\n",
    "# If test data has separate prompt and responses, create 'text_input' same way as train\n",
    "# For example, if columns are 'prompt', 'response_a', 'response_b', do:\n",
    "\n",
    "# test_df[\"text_input\"] = (\n",
    "#     \"Prompt: \" + test_df[\"prompt\"].astype(str) +\n",
    "#     \"\\nResponse A: \" + test_df[\"response_a\"].astype(str) +\n",
    "#     \"\\nResponse B: \" + test_df[\"response_b\"].astype(str)\n",
    "# )\n",
    "\n",
    "# If test already has 'text_input' column like train, then just:\n",
    "test_df[\"text_input\"] = test_df[\"text_input\"].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "# Vectorize test text using the same TF-IDF vectorizer fitted on train data\n",
    "X_test = tfidf.transform(test_df[\"text_input\"])\n",
    "\n",
    "# Predict with trained model\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# Map predictions back to labels \"A\" or \"B\"\n",
    "inv_label_map = {0: \"A\", 1: \"B\"}\n",
    "test_df[\"winner\"] = [inv_label_map[p] for p in test_preds]\n",
    "\n",
    "print(test_df[[\"winner\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "245de491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final_submission.csv\n"
     ]
    }
   ],
   "source": [
    "sample_sub = pd.read_csv(\"/Users/pennatarunkumar/Documents/llm-classification-finetuning/sample_submission.csv\")\n",
    "\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission[\"winner\"] = test_df[\"winner\"]\n",
    "\n",
    "submission.to_csv(\"final_submission.csv\", index=False)\n",
    "print(\"Saved final_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d846f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
